{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee9ace3c",
   "metadata": {},
   "source": [
    "## Cell 1: Imports & Configuration\n",
    "\n",
    "Sets up your environment and professional display settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf499d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORTS & CONFIGURATION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Professional Tip: Set pandas display options to see all columns during inspection\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Load Dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(\"Data Loaded. Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcac23e",
   "metadata": {},
   "source": [
    "## Cell 2: The \"Sanity Check\" (Audit)\n",
    "Checks for duplicates and distinct values to ensure data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c15ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for full row duplicates (common in SQL extraction errors)\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate Rows Detected: {duplicates}\")\n",
    "\n",
    "# Drop duplicates if any\n",
    "if duplicates > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(\"Duplicates dropped.\")\n",
    "\n",
    "# Check cardinality (number of unique values) to identify ID columns or constants\n",
    "print(\"\\n--- Unique Values per Column ---\")\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49663c42",
   "metadata": {},
   "source": [
    "## Cell 3: Numpy Statistical Analysis (Outliers)\n",
    "\n",
    "Uses Numpy to check for skewed data (like expensive tickets) using Z-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed32ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMPY USAGE: outlier detection using Z-scores manually\n",
    "# We want to see how 'fare' is distributed. Is it skewed?\n",
    "fare_values = df['fare'].dropna().values # Extract numpy array\n",
    "\n",
    "mean_fare = np.mean(fare_values)\n",
    "std_fare = np.std(fare_values)\n",
    "\n",
    "# Find fares that are 3 standard deviations away (Outliers)\n",
    "outliers = fare_values[np.abs(fare_values - mean_fare) > 3 * std_fare]\n",
    "print(f\"Max Fare: {np.max(fare_values)}\")\n",
    "print(f\"Number of extreme outliers (3 sigma): {len(outliers)}\")\n",
    "\n",
    "# Visual Check\n",
    "sns.histplot(df['fare'], kde=True)\n",
    "plt.title('Fare Distribution (Skewed Check)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705b6a73",
   "metadata": {},
   "source": [
    "## Cell 4: Feature Engineering (Vectorized Logic)\n",
    "\n",
    "Uses np.where and np.select to create new columns significantly faster than standard loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGIC: If a person is alone (no siblings/spouse/parents), they might have lower survival.\n",
    "df['family_size'] = df['sibsp'] + df['parch']\n",
    "\n",
    "# Syntax: np.where(condition, value_if_true, value_if_false)\n",
    "df['is_alone'] = np.where(df['family_size'] == 0, 1, 0)\n",
    "\n",
    "# LOGIC: Create a complexity tier for Age using np.select (like SQL CASE WHEN)\n",
    "conditions = [\n",
    "    (df['age'] < 12),\n",
    "    (df['age'] >= 12) & (df['age'] < 60),\n",
    "    (df['age'] >= 60)\n",
    "]\n",
    "choices = ['child', 'adult', 'senior']\n",
    "\n",
    "df['age_group'] = np.select(conditions, choices, default='unknown')\n",
    "\n",
    "print(df[['age', 'age_group', 'is_alone']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2fb59f",
   "metadata": {},
   "source": [
    "## Cell 5: Smart Cleaning\n",
    "\n",
    "Decides how to handle missing data based on percentages rather than guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check percentage of missing values\n",
    "missing_percent = df.isnull().mean() * 100\n",
    "print(missing_percent[missing_percent > 0])\n",
    "\n",
    "# DECISION LOGIC:\n",
    "# 1. 'deck' has too many missing (~77%). DROP it.\n",
    "# 2. 'age' is missing ~20%. IMPUTE it with Median (robust to outliers).\n",
    "# 3. 'embarked' is missing very few. DROP rows.\n",
    "\n",
    "df_clean = df.drop(columns=['deck'])\n",
    "df_clean['age'] = df_clean['age'].fillna(df_clean['age'].median())\n",
    "df_clean = df_clean.dropna(subset=['embarked_town'])\n",
    "\n",
    "print(\"Shape after cleaning:\", df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf77181",
   "metadata": {},
   "source": [
    "## Cell 6: Mathematical Transformations\n",
    "\n",
    "Normalizes skewed data (like money) to help the model learn better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1dfc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Fare' was highly skewed. Let's apply Log transformation.\n",
    "# We use np.log1p (log(1+x)) to avoid errors with 0 values.\n",
    "df_clean['fare_log'] = np.log1p(df_clean['fare'])\n",
    "\n",
    "# Compare variances\n",
    "print(f\"Original Variance: {np.var(df_clean['fare']):.2f}\")\n",
    "print(f\"Log Variance: {np.var(df_clean['fare_log']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fdd828",
   "metadata": {},
   "source": [
    "## Cell 7: Final Prep (Encoding & Splitting)\n",
    "\n",
    "Prepares the final arrays for Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'sex' to binary\n",
    "df_clean['sex_binary'] = np.where(df_clean['sex'] == 'male', 0, 1)\n",
    "\n",
    "# One-Hot Encode 'embarked_town' and 'class'\n",
    "df_final = pd.get_dummies(df_clean, columns=['embarked_town', 'class'], drop_first=True)\n",
    "\n",
    "# Select Features for the model\n",
    "features = ['pclass', 'sex_binary', 'age', 'sibsp', 'parch', 'fare_log', 'is_alone']\n",
    "X = df_final[features]\n",
    "y = df_final['survived']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Testing Data Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff22724",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e78b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
