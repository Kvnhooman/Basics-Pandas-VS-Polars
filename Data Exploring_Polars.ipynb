{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "106a2fae",
   "metadata": {},
   "source": [
    "### Cell 1: Imports & Loading\n",
    "\n",
    "Polars doesn't have built-in datasets, so we load via pandas first and convert. This is a very common workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aeeaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load data via Seaborn (returns Pandas)\n",
    "pandas_df = sns.load_dataset('titanic')\n",
    "\n",
    "# 2. Convert to Polars (The \"Pro\" Switch)\n",
    "df = pl.from_pandas(pandas_df)\n",
    "\n",
    "print(\"Polars Data Loaded. Shape:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80230d8e",
   "metadata": {},
   "source": [
    "### Cell 2: The \"Sanity Check\" (Audit)\n",
    "\n",
    "Polars provides glimpse() which is often better than info() because it shows you sample data immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick audit of structure and types\n",
    "print(\"--- Glimpse ---\")\n",
    "print(df.glimpse())\n",
    "\n",
    "# Check for duplicates\n",
    "n_dupes = df.is_duplicated().sum()\n",
    "print(f\"\\nDuplicate Rows: {n_dupes}\")\n",
    "\n",
    "# Remove duplicates (distinct)\n",
    "if n_dupes > 0:\n",
    "    df = df.unique()\n",
    "\n",
    "# Check cardinality (Unique values)\n",
    "print(\"\\n--- Unique Values per Column ---\")\n",
    "# select(pl.all().n_unique()) runs this check on every column in parallel\n",
    "print(df.select(pl.all().n_unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2567de0",
   "metadata": {},
   "source": [
    "### Cell 3: Statistical Analysis (Outliers)\n",
    "\n",
    "Notice the syntax change: we use filter explicitly rather than boolean indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1bd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Stats for 'fare'\n",
    "stats = df.select([\n",
    "    pl.col(\"fare\").mean().alias(\"mean\"),\n",
    "    pl.col(\"fare\").std().alias(\"std\"),\n",
    "    pl.col(\"fare\").max().alias(\"max\")\n",
    "])\n",
    "\n",
    "mean_fare = stats[\"mean\"][0]\n",
    "std_fare = stats[\"std\"][0]\n",
    "\n",
    "# Filter for Outliers (3 Sigma rule)\n",
    "# We use .filter( condition )\n",
    "outliers = df.filter(\n",
    "    (pl.col(\"fare\") - mean_fare).abs() > (3 * std_fare)\n",
    ")\n",
    "\n",
    "print(f\"Number of extreme outliers: {outliers.height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6587ad",
   "metadata": {},
   "source": [
    "### Cell 4: Feature Engineering (The Expression API)\n",
    "\n",
    "This is where Polars shines. Instead of np.where, we use the readable chain: when().then().otherwise()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Polars, we use .with_columns() to add/modify columns\n",
    "df = df.with_columns([\n",
    "    # logic 1: Family Size\n",
    "    (pl.col(\"sibsp\") + pl.col(\"parch\")).alias(\"family_size\")\n",
    "])\n",
    "\n",
    "# logic 2: Is Alone? & Age Group\n",
    "# We can chain multiple creations inside one .with_columns() call for speed\n",
    "df = df.with_columns([\n",
    "    \n",
    "    pl.when(pl.col(\"family_size\") == 0)\n",
    "      .then(1)\n",
    "      .otherwise(0)\n",
    "      .alias(\"is_alone\"),\n",
    "      \n",
    "    pl.when(pl.col(\"age\") < 12).then(pl.lit(\"child\"))\n",
    "      .when(pl.col(\"age\") < 60).then(pl.lit(\"adult\"))\n",
    "      .otherwise(pl.lit(\"senior\"))\n",
    "      .alias(\"age_group\")\n",
    "])\n",
    "\n",
    "print(df.select([\"age\", \"age_group\", \"is_alone\"]).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2574b662",
   "metadata": {},
   "source": [
    "### Cell 5: Smart Cleaning\n",
    "\n",
    "Polars handles nulls explicitly. We filter out the 'deck' column using drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0dd1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null counts\n",
    "print(df.null_count())\n",
    "\n",
    "# DECISION LOGIC:\n",
    "# 1. Drop 'deck'\n",
    "df_clean = df.drop(\"deck\")\n",
    "\n",
    "# 2. Impute 'age' with Median\n",
    "# We calculate the median first, then fill\n",
    "age_median = df_clean.select(pl.col(\"age\").median()).item()\n",
    "df_clean = df_clean.with_columns(\n",
    "    pl.col(\"age\").fill_null(age_median)\n",
    ")\n",
    "\n",
    "# 3. Drop rows where 'embarked_town' is null\n",
    "df_clean = df_clean.drop_nulls(subset=[\"embarked_town\"])\n",
    "\n",
    "print(\"Shape after cleaning:\", df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873473a6",
   "metadata": {},
   "source": [
    "### Cell 6: Mathematical Transformations\n",
    "\n",
    "Polars has built-in math functions that are highly optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Transform Fare\n",
    "# pl.col(\"fare\").log1p() is the equivalent of np.log1p()\n",
    "df_clean = df_clean.with_columns(\n",
    "    pl.col(\"fare\").log1p().alias(\"fare_log\")\n",
    ")\n",
    "\n",
    "# Show variance comparison\n",
    "# We use .var() aggregation\n",
    "print(df_clean.select([\n",
    "    pl.col(\"fare\").var().alias(\"Original Variance\"),\n",
    "    pl.col(\"fare_log\").var().alias(\"Log Variance\")\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22018130",
   "metadata": {},
   "source": [
    "### Cell 7: Final Prep (Encoding & Splitting)\n",
    "\n",
    "Polars has to_dummies for One-Hot Encoding. Since Scikit-Learn expects numpy/pandas arrays generally, we convert back right at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a6493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Binary Encode Sex (Male=0, Female=1)\n",
    "# cast(pl.Int8) turns the boolean (True/False) into 1/0\n",
    "df_clean = df_clean.with_columns(\n",
    "    (pl.col(\"sex\") == \"female\").cast(pl.Int8).alias(\"sex_binary\")\n",
    ")\n",
    "\n",
    "# 2. One Hot Encode Town & Class\n",
    "df_final = df_clean.to_dummies([\"embarked_town\", \"class\"], drop_first=True)\n",
    "\n",
    "# 3. Select Features\n",
    "features = ['pclass', 'sex_binary', 'age', 'sibsp', 'parch', 'fare_log', 'is_alone']\n",
    "\n",
    "# 4. Extract to Numpy/Pandas for Scikit-Learn Compatibility\n",
    "# (Most ML libraries still expect standard arrays)\n",
    "X = df_final.select(features).to_pandas()\n",
    "y = df_final.select(\"survived\").to_pandas()['survived']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Testing Data Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa7344",
   "metadata": {},
   "source": [
    "#### Key Polars \"Gotchas\" to remember:\n",
    "\n",
    "pl.col(\"name\"): You rarely use strings directly (like df['name']). You almost always wrap them in pl.col().\n",
    "\n",
    "with_columns: You cannot just say df['new_col'] = x. You must use df = df.with_columns(...). This ensures the operations are parallelized.\n",
    "\n",
    "alias: If you do math on a column, it keeps the old name unless you use .alias(\"new_name\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d4e40",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
